2024-02-16 02:42:13,080 INFO =============A WHOLE TRAINING PERIOD ENDED=============
2024-02-16 02:42:13,087 INFO agent_timesteps_total: 10000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0038683414459228516
  StateBufferConnector_ms: 0.0021631717681884766
  ViewRequirementAgentConnector_ms: 0.04478955268859863
counters:
  num_agent_steps_sampled: 10000
  num_agent_steps_trained: 0
  num_env_steps_sampled: 10000
  num_env_steps_trained: 0
custom_metrics: {}
date: 2024-02-16_02-42-13
done: false
episode_len_mean: 99.12
episode_media: {}
episode_reward_max: -1745.1761498218777
episode_reward_mean: -15603.8903513508
episode_reward_min: -21596.22973861886
episodes_this_iter: 1
episodes_total: 100
evaluation:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0024159749348958335
    StateBufferConnector_ms: 0.0015497207641601562
    ViewRequirementAgentConnector_ms: 0.03732840220133463
  custom_metrics: {}
  episode_len_mean: 100.0
  episode_media: {}
  episode_reward_max: -10221.954445729292
  episode_reward_mean: -12179.57689549172
  episode_reward_min: -15189.24439894495
  episodes_this_iter: 3
  hist_stats:
    episode_lengths:
    - 100
    - 100
    - 100
    episode_reward:
    - -11127.531841800921
    - -10221.954445729292
    - -15189.24439894495
  num_agent_steps_sampled_this_iter: 300
  num_env_steps_sampled_this_iter: 300
  num_faulty_episodes: 0
  num_healthy_workers: 0
  num_in_flight_async_reqs: 0
  num_remote_worker_restarts: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.035326407991295314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.350533870143783
    mean_inference_ms: 0.5501519878333158
    mean_raw_obs_processing_ms: 0.1139871986948376
  sampler_results:
    connector_metrics:
      ObsPreprocessorConnector_ms: 0.0024159749348958335
      StateBufferConnector_ms: 0.0015497207641601562
      ViewRequirementAgentConnector_ms: 0.03732840220133463
    custom_metrics: {}
    episode_len_mean: 100.0
    episode_media: {}
    episode_reward_max: -10221.954445729292
    episode_reward_mean: -12179.57689549172
    episode_reward_min: -15189.24439894495
    episodes_this_iter: 3
    hist_stats:
      episode_lengths:
      - 100
      - 100
      - 100
      episode_reward:
      - -11127.531841800921
      - -10221.954445729292
      - -15189.24439894495
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.035326407991295314
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 11.350533870143783
      mean_inference_ms: 0.5501519878333158
      mean_raw_obs_processing_ms: 0.1139871986948376
  timesteps_this_iter: 300
hostname: OrangeBookPro14.lan
info:
  learner: {}
  num_agent_steps_sampled: 10000
  num_agent_steps_trained: 0
  num_env_steps_sampled: 10000
  num_env_steps_trained: 0
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 10000
num_agent_steps_trained: 0
num_env_steps_sampled: 10000
num_env_steps_sampled_this_iter: 100
num_env_steps_sampled_throughput_per_sec: 81.83164739320515
num_env_steps_trained: 0
num_env_steps_trained_this_iter: 0
num_env_steps_trained_throughput_per_sec: 0.0
num_faulty_episodes: 0
num_healthy_workers: 1
num_in_flight_async_reqs: 0
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 0
perf:
  cpu_util_percent: 31.957142857142856
  ram_util_percent: 80.74285714285715
pid: 13063
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.03634390417246309
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 11.400920804206475
  mean_inference_ms: 0.7033412899696914
  mean_raw_obs_processing_ms: 0.24458432474059524
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0038683414459228516
    StateBufferConnector_ms: 0.0021631717681884766
    ViewRequirementAgentConnector_ms: 0.04478955268859863
  custom_metrics: {}
  episode_len_mean: 99.12
  episode_media: {}
  episode_reward_max: -1745.1761498218777
  episode_reward_mean: -15603.8903513508
  episode_reward_min: -21596.22973861886
  episodes_this_iter: 1
  hist_stats:
    episode_lengths: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 12, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100]
    episode_reward: [-15408.915278441733, -15461.186552974948, -13815.924110785612,
      -17198.449822145594, -16477.847244900375, -12893.910676114117, -14677.53845160566,
      -13959.902005815347, -16654.37471799315, -12180.071423545394, -13901.682914942196,
      -16462.73501222297, -15790.993258376278, -15106.940155847613, -14753.942218706039,
      -14850.374126392417, -17744.08992153781, -15288.602980252756, -19580.04993938005,
      -12815.130699869238, -16786.300976943363, -15741.215179818582, -16737.444204428495,
      -15304.389394262425, -14189.11604711618, -16416.690541412314, -15696.177124933849,
      -16120.980377529426, -15393.218689510202, -12530.716729149199, -13983.336954442964,
      -15524.121265992784, -15213.10602690341, -14812.130275458918, -15877.467724437342,
      -1745.1761498218777, -16143.80032889482, -15819.519264476312, -20760.58656210036,
      -12795.00259509774, -14993.415437414593, -16860.244363688096, -14807.095708050003,
      -15666.349208619296, -15480.019988836108, -15358.70674517471, -18535.065527152972,
      -17191.96448882627, -14739.608292527855, -13538.117379415904, -16499.390208322737,
      -18189.36300442435, -16289.825933098267, -14878.392150502781, -15175.920238555987,
      -13551.010334478895, -16721.226632887043, -13673.329776477618, -16943.291098867518,
      -14978.989619963262, -16033.00635780384, -17685.916841945298, -16857.70596220446,
      -14497.65062277507, -18708.77298074022, -14740.852657909469, -16308.076729184997,
      -17988.615849401245, -17448.68256879263, -15642.403289866666, -21051.942750466405,
      -14994.6462735963, -18085.298756949484, -13843.658381426269, -13759.533346148,
      -14126.479574283274, -21596.22973861886, -18114.88218999681, -13831.580945101832,
      -14673.97599770875, -17224.73345223255, -13822.413625653071, -13077.75418791752,
      -14961.000475779056, -15104.520813288067, -13279.144687341397, -20684.04697297682,
      -14480.484798646912, -14401.244621095308, -11551.426211766186, -16792.222615906572,
      -17320.66047422428, -13382.36723746115, -14139.37028212606, -21354.53561119326,
      -17382.58320207552, -18869.040260865004, -19174.403762660186, -14703.350826052494,
      -12009.335139034336]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.03634390417246309
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.400920804206475
    mean_inference_ms: 0.7033412899696914
    mean_raw_obs_processing_ms: 0.24458432474059524
time_since_restore: 502.51943731307983
time_this_iter_s: 5.242213726043701
time_total_s: 502.51943731307983
timers:
  sample_time_ms: 12.206
  training_iteration_time_ms: 12.304
timestamp: 1708080133
timesteps_total: 10000
training_iteration: 100
trial_id: default

2024-02-16 02:42:13,087 DEBUG {'env': {'cropped_map_size': 64, 'ratio_coverage': 0.0125, 'original_map_path': '/Users/ylu/Documents/USC/WiDeS/BS_Deployment/resource/usc.png', 'original_map_scale': 3.4375, 'n_maps': 10, 'n_steps_per_map': 100, 'no_masking': True, 'coefficient_dict': {'r_c': 1.0, 'p_d': 1.0, 'p_b': 1.0}}, 'explore': {'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 20000}}, 'train': {'train_batch_size': 32, 'num_steps_sampled_before_learning_starts': 10000, 'replay_buffer_config': {'capacity': 20000}}, 'eval': {'evaluation_interval': 1, 'evaluation_duration': 3, 'evaluation_config': {'explore': False}}, 'stop': {'training_iteration': 20}}
2024-02-16 04:53:42,697 INFO =============A WHOLE TRAINING PERIOD ENDED=============
2024-02-16 04:53:42,706 INFO agent_timesteps_total: 100000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0055887699127197266
  StateBufferConnector_ms: 0.0027549266815185547
  ViewRequirementAgentConnector_ms: 0.0919804573059082
counters:
  last_target_update_ts: 100000
  num_agent_steps_sampled: 100000
  num_agent_steps_trained: 2880000
  num_env_steps_sampled: 100000
  num_env_steps_trained: 2880000
  num_target_updates: 90000
custom_metrics: {}
date: 2024-02-16_04-53-42
done: false
episode_len_mean: 100.0
episode_media: {}
episode_reward_max: -1188.1390690862513
episode_reward_mean: -10608.552027860598
episode_reward_min: -15419.081706789311
episodes_this_iter: 10
episodes_total: 1000
evaluation:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0020106633504231772
    StateBufferConnector_ms: 0.0014464060465494792
    ViewRequirementAgentConnector_ms: 0.0310818354288737
  custom_metrics: {}
  episode_len_mean: 100.0
  episode_media: {}
  episode_reward_max: -14240.063693621545
  episode_reward_mean: -15343.351996485595
  episode_reward_min: -16244.99614791762
  episodes_this_iter: 3
  hist_stats:
    episode_lengths:
    - 100
    - 100
    - 100
    episode_reward:
    - -15544.996147917618
    - -16244.99614791762
    - -14240.063693621545
  num_agent_steps_sampled_this_iter: 300
  num_env_steps_sampled_this_iter: 300
  num_faulty_episodes: 0
  num_healthy_workers: 0
  num_in_flight_async_reqs: 0
  num_remote_worker_restarts: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.031285951751132225
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 10.973655860831963
    mean_inference_ms: 0.5036602774912793
    mean_raw_obs_processing_ms: 0.10565047955331014
  sampler_results:
    connector_metrics:
      ObsPreprocessorConnector_ms: 0.0020106633504231772
      StateBufferConnector_ms: 0.0014464060465494792
      ViewRequirementAgentConnector_ms: 0.0310818354288737
    custom_metrics: {}
    episode_len_mean: 100.0
    episode_media: {}
    episode_reward_max: -14240.063693621545
    episode_reward_mean: -15343.351996485595
    episode_reward_min: -16244.99614791762
    episodes_this_iter: 3
    hist_stats:
      episode_lengths:
      - 100
      - 100
      - 100
      episode_reward:
      - -15544.996147917618
      - -16244.99614791762
      - -14240.063693621545
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.031285951751132225
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 10.973655860831963
      mean_inference_ms: 0.5036602774912793
      mean_raw_obs_processing_ms: 0.10565047955331014
  timesteps_this_iter: 300
hostname: OrangeBookPro14.lan
info:
  last_target_update_ts: 100000
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 89999.0
      learner_stats:
        actor_loss: 10464.9345703125
        allreduce_latency: 0.0
        alpha_loss: -221.23191833496094
        alpha_value: 612198055936.0
        critic_loss: 4.858701705932617
        grad_gnorm: 8.151411056518555
        log_alpha_value: 27.140321731567383
        max_q: 26.541534423828125
        mean_q: -7931.052734375
        min_q: -16497.322265625
        policy_t: 0.000244140625
        target_entropy: 8.151411056518555
      mean_td_error: 25.99674415588379
      model: {}
      num_agent_steps_trained: 32.0
      num_grad_updates_lifetime: 90000.0
      td_error: [7.92431640625, 10.90185546875, 30.64697265625, 10.90185546875, 10.90185546875,
        22.967529296875, 2.98583984375, 130.5615234375, 13.96142578125, 21.64697265625,
        7.92431640625, 13.96142578125, 7.19775390625, 7.92431640625, 10.2783203125,
        10.90185546875, 23.81103515625, 3.216796875, 2.98583984375, 11.69195556640625,
        30.64697265625, 20.76611328125, 13.96142578125, 284.32275390625, 7.19775390625,
        2.55859375, 5.7216796875, 30.64697265625, 22.967529296875, 19.64697265625,
        7.19775390625, 22.967529296875]
  num_agent_steps_sampled: 100000
  num_agent_steps_trained: 2880000
  num_env_steps_sampled: 100000
  num_env_steps_trained: 2880000
  num_target_updates: 90000
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 100000
num_agent_steps_trained: 2880000
num_env_steps_sampled: 100000
num_env_steps_sampled_this_iter: 1000
num_env_steps_sampled_throughput_per_sec: 13.24921301461849
num_env_steps_trained: 2880000
num_env_steps_trained_this_iter: 32000
num_env_steps_trained_throughput_per_sec: 423.9748164677917
num_faulty_episodes: 0
num_healthy_workers: 1
num_in_flight_async_reqs: 0
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 32000
perf:
  cpu_util_percent: 22.033035714285713
  ram_util_percent: 80.05892857142858
pid: 13478
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.044426566164953
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 11.44442294672484
  mean_inference_ms: 0.8524254697478745
  mean_raw_obs_processing_ms: 0.3502034457599181
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0055887699127197266
    StateBufferConnector_ms: 0.0027549266815185547
    ViewRequirementAgentConnector_ms: 0.0919804573059082
  custom_metrics: {}
  episode_len_mean: 100.0
  episode_media: {}
  episode_reward_max: -1188.1390690862513
  episode_reward_mean: -10608.552027860598
  episode_reward_min: -15419.081706789311
  episodes_this_iter: 10
  hist_stats:
    episode_lengths: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,
      100, 100, 100, 100, 100, 100, 100, 100]
    episode_reward: [-10444.200071649653, -13517.29043358775, -9062.32703549278, -14416.30761174081,
      -13050.528627946673, -9036.8147610538, -11313.344218749753, -11336.0679774998,
      -10699.689895004874, -11595.212440142532, -11513.608305156182, -9697.503556109159,
      -7957.165716661152, -9847.16107275425, -14324.669653925443, -8886.16960546906,
      -10196.868638427186, -14179.503914973422, -12482.718455881215, -13191.755282131568,
      -5942.887451746169, -8966.07627338611, -7754.582478537381, -11520.969135567253,
      -14135.19669896634, -10676.921478740784, -12707.535884528586, -14177.264865358158,
      -15283.650066971004, -11148.25130147012, -14360.80905878752, -10737.60585556816,
      -12319.535622777777, -10480.282864072251, -9593.141849091735, -13520.772469410911,
      -10285.538224105276, -15419.081706789311, -2182.842712474621, -12213.608305156184,
      -13142.114763410455, -10629.922914390101, -9010.217860157256, -11429.882102172183,
      -9509.361393549028, -11677.42542996314, -10636.0679774998, -6708.707068617014,
      -12162.83552696398, -11312.64994427896, -9879.113173467245, -11523.014285349873,
      -12349.778803095109, -5750.982500219446, -12182.84271247462, -9638.540852988901,
      -13456.028666680792, -13789.789376054407, -6745.187378732392, -15022.03589590872,
      -13199.858006897632, -4980.446701676663, -7979.217646178665, -1608.9680950855268,
      -11282.770398228071, -10163.98501970892, -9913.274595042154, -10760.931937264037,
      -13610.786194085456, -6581.495481311969, -10958.567932877748, -8895.555661743232,
      -11204.465011904798, -14307.631981610468, -1188.1390690862513, -4985.051135210729,
      -6183.1634347253685, -10777.04199416519, -12078.657748896327, -2582.2044665438257,
      -9713.274595042156, -10635.373390120545, -9040.001050340403, -11080.120829709676,
      -10801.455456429874, -8828.30379126923, -9935.822578726384, -12665.949227904253,
      -11840.312423743302, -13943.938198037118, -11055.501735165863, -11482.842712474618,
      -8486.654418759512, -6609.804234161358, -14202.271554554503, -12392.823797171817,
      -10016.095238760572, -11894.262351449273, -12413.608305156185, -13842.614181003906]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.044426566164953
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.44442294672484
    mean_inference_ms: 0.8524254697478745
    mean_raw_obs_processing_ms: 0.3502034457599181
time_since_restore: 7386.156136274338
time_this_iter_s: 78.98432183265686
time_total_s: 7386.156136274338
timers:
  learn_throughput: 1614.478
  learn_time_ms: 19.821
  load_throughput: 532187.661
  load_time_ms: 0.06
  sample_time_ms: 32.618
  synch_weights_time_ms: 3.033
  training_iteration_time_ms: 73.698
timestamp: 1708088022
timesteps_total: 100000
training_iteration: 100
trial_id: default

2024-02-16 04:53:42,706 DEBUG {'env': {'cropped_map_size': 64, 'ratio_coverage': 0.0125, 'original_map_path': '/Users/ylu/Documents/USC/WiDeS/BS_Deployment/resource/usc.png', 'original_map_scale': 3.4375, 'n_maps': 10, 'n_steps_per_map': 100, 'no_masking': True, 'coefficient_dict': {'r_c': 1.0, 'p_d': 1.0, 'p_b': 1.0}}, 'explore': {'explore': True, 'exploration_config': {'type': 'EpsilonGreedy', 'initial_epsilon': 1.0, 'final_epsilon': 0.02, 'epsilon_timesteps': 20000}}, 'train': {'train_batch_size': 32, 'num_steps_sampled_before_learning_starts': 10000, 'replay_buffer_config': {'capacity': 20000}}, 'eval': {'evaluation_interval': 1, 'evaluation_duration': 3, 'evaluation_config': {'explore': False}}, 'report': {'min_sample_timesteps_per_iteration': 1000}, 'stop': {'training_iteration': 20}}
2024-02-22 01:32:17,313 INFO ================EVALUATION AT # 5================
2024-02-22 01:32:23,651 INFO ================EVALUATION AT # 10================
2024-02-22 01:32:25,557 INFO =============A WHOLE TRAINING PERIOD ENDED=============
2024-02-22 01:32:25,564 INFO agent_timesteps_total: 260
connector_metrics:
  ObsPreprocessorConnector_ms: 0.009449323018391928
  StateBufferConnector_ms: 0.006453196207682292
  ViewRequirementAgentConnector_ms: 0.18451809883117676
counters:
  last_target_update_ts: 260
  num_agent_steps_sampled: 260
  num_agent_steps_trained: 8064
  num_env_steps_sampled: 260
  num_env_steps_trained: 8064
  num_target_updates: 63
custom_metrics: {}
date: 2024-02-22_01-32-25
done: false
episode_len_mean: 20.0
episode_media: {}
episode_reward_max: -1886.9117035996208
episode_reward_mean: -2693.7407369673297
episode_reward_min: -3335.5165988733743
episodes_this_iter: 4
episodes_total: 12
evaluation:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.005539258321126302
    StateBufferConnector_ms: 0.0024318695068359375
    ViewRequirementAgentConnector_ms: 0.04572073618570963
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -2646.7484132816953
  episode_reward_mean: -2890.0956423651464
  episode_reward_min: -3283.5385138137435
  episodes_this_iter: 3
  hist_stats:
    episode_lengths:
    - 20
    - 20
    - 20
    episode_reward:
    - -2646.7484132816953
    - -2740.0
    - -3283.5385138137435
  num_agent_steps_sampled_this_iter: 60
  num_env_steps_sampled_this_iter: 60
  num_faulty_episodes: 0
  num_healthy_workers: 0
  num_in_flight_async_reqs: 0
  num_remote_worker_restarts: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.041599116049522204
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.156562931281476
    mean_inference_ms: 0.6290368797365298
    mean_raw_obs_processing_ms: 0.15357703216804944
  sampler_results:
    connector_metrics:
      ObsPreprocessorConnector_ms: 0.005539258321126302
      StateBufferConnector_ms: 0.0024318695068359375
      ViewRequirementAgentConnector_ms: 0.04572073618570963
    custom_metrics: {}
    episode_len_mean: 20.0
    episode_media: {}
    episode_reward_max: -2646.7484132816953
    episode_reward_mean: -2890.0956423651464
    episode_reward_min: -3283.5385138137435
    episodes_this_iter: 3
    hist_stats:
      episode_lengths:
      - 20
      - 20
      - 20
      episode_reward:
      - -2646.7484132816953
      - -2740.0
      - -3283.5385138137435
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.041599116049522204
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 11.156562931281476
      mean_inference_ms: 0.6290368797365298
      mean_raw_obs_processing_ms: 0.15357703216804944
  timesteps_this_iter: 60
hostname: OrangeBookPro14.lan
info:
  last_target_update_ts: 260
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 62.0
      learner_stats:
        actor_loss: -8.109224319458008
        allreduce_latency: 0.0
        alpha_loss: -0.0005798927159048617
        alpha_value: 0.9939429759979248
        critic_loss: 13.006547927856445
        grad_gnorm: 0.09544829279184341
        log_alpha_value: -0.006075464654713869
        max_q: 1.6864080429077148
        mean_q: -2.3391358852386475
        min_q: -729.7362060546875
        policy_t: 0.000244140625
        target_entropy: 8.151411056518555
      mean_td_error: 37.204593658447266
      model: {}
      num_agent_steps_trained: 128.0
      num_grad_updates_lifetime: 63.0
      td_error: [9.669471740722656, 39.36475372314453, 27.947593688964844, 55.09463882446289,
        22.01641082763672, 53.73798370361328, 28.886611938476562, 12.21688461303711,
        13.2982177734375, 53.73798370361328, 29.882232666015625, 33.792388916015625,
        8.874160766601562, 37.676361083984375, 52.81970977783203, 90.88082122802734,
        10.264263153076172, 39.88363265991211, 3.5165634155273438, 55.09463882446289,
        38.03040313720703, 29.575511932373047, 148.62017822265625, 17.292617797851562,
        39.88363265991211, 73.18111419677734, 148.62017822265625, 33.792388916015625,
        71.53112030029297, 1.6574325561523438, 102.57438659667969, 53.73798370361328,
        36.59539031982422, 55.09463882446289, 71.53112030029297, 20.64893341064453,
        49.82157897949219, 22.01641082763672, 29.882232666015625, 3.5165634155273438,
        49.82157897949219, 1.6574325561523438, 0.6914024353027344, 53.73798370361328,
        29.007965087890625, 29.45232391357422, 6.506111145019531, 36.59539031982422,
        49.82157897949219, 39.630653381347656, 9.669471740722656, 39.36475372314453,
        71.53112030029297, 33.792388916015625, 55.09463882446289, 20.64893341064453,
        18.414138793945312, 13.2982177734375, 6.506111145019531, 39.630653381347656,
        39.32920837402344, 90.88082122802734, 90.88082122802734, 49.82157897949219,
        20.64893341064453, 11.926033020019531, 37.371055603027344, 36.59539031982422,
        53.73798370361328, 7.962303161621094, 22.01641082763672, 33.792388916015625,
        0.6914024353027344, 3.5165634155273438, 32.154296875, 33.267879486083984,
        9.669471740722656, 42.227073669433594, 55.09463882446289, 22.01641082763672,
        36.59539031982422, 22.01641082763672, 53.73798370361328, 39.36475372314453,
        28.886611938476562, 55.09463882446289, 53.73798370361328, 33.267879486083984,
        37.676361083984375, 20.64893341064453, 29.007965087890625, 37.676361083984375,
        5.062065124511719, 1.6574325561523438, 11.926033020019531, 53.73798370361328,
        7.348091125488281, 24.95330810546875, 148.62017822265625, 10.264263153076172,
        17.292617797851562, 1.6574325561523438, 53.73798370361328, 102.57438659667969,
        39.630653381347656, 33.792388916015625, 55.09463882446289, 7.962303161621094,
        9.669471740722656, 9.669471740722656, 39.630653381347656, 37.371055603027344,
        71.53112030029297, 29.007965087890625, 39.630653381347656, 34.337120056152344,
        39.88363265991211, 36.59539031982422, 33.267879486083984, 55.09463882446289,
        53.73798370361328, 6.506111145019531, 33.267879486083984, 22.01641082763672,
        53.73798370361328, 52.81970977783203, 39.36475372314453, 17.292617797851562]
  num_agent_steps_sampled: 260
  num_agent_steps_trained: 8064
  num_env_steps_sampled: 260
  num_env_steps_trained: 8064
  num_target_updates: 63
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 260
num_agent_steps_trained: 8064
num_env_steps_sampled: 260
num_env_steps_sampled_this_iter: 32
num_env_steps_sampled_throughput_per_sec: 28.560615517005473
num_env_steps_trained: 8064
num_env_steps_trained_this_iter: 1024
num_env_steps_trained_throughput_per_sec: 913.9396965441751
num_faulty_episodes: 0
num_healthy_workers: 4
num_in_flight_async_reqs: 0
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 1024
perf:
  cpu_util_percent: 32.53333333333333
  ram_util_percent: 80.93333333333334
pid: 96519
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.12387578277532846
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 11.943068188678309
  mean_inference_ms: 2.0492367478676172
  mean_raw_obs_processing_ms: 1.2004599727765477
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.009449323018391928
    StateBufferConnector_ms: 0.006453196207682292
    ViewRequirementAgentConnector_ms: 0.18451809883117676
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -1886.9117035996208
  episode_reward_mean: -2693.7407369673297
  episode_reward_min: -3335.5165988733743
  episodes_this_iter: 4
  hist_stats:
    episode_lengths: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
    episode_reward: [-2623.551223160349, -2945.926603061495, -3335.5165988733743,
      -2812.6831542126365, -2415.683539409991, -2131.8312909550677, -3090.4383150870813,
      -3070.3082498683693, -2434.200471807446, -2577.027549406952, -3000.810144165577,
      -1886.9117035996208]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12387578277532846
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.943068188678309
    mean_inference_ms: 2.0492367478676172
    mean_raw_obs_processing_ms: 1.2004599727765477
time_since_restore: 13.038374900817871
time_this_iter_s: 1.8972830772399902
time_total_s: 13.038374900817871
timers:
  learn_throughput: 4800.846
  learn_time_ms: 26.662
  load_throughput: 1837969.572
  load_time_ms: 0.07
  sample_time_ms: 58.254
  synch_weights_time_ms: 32.199
  training_iteration_time_ms: 145.056
timestamp: 1708594345
timesteps_total: 260
training_iteration: 10
trial_id: default

2024-02-22 01:32:25,564 DEBUG {'env': {'coefficient_dict': {'p_b': 1.0, 'p_d': 1.0, 'r_c': 0.1}, 'cropped_map_size': 64, 'n_maps': 100, 'n_steps_per_map': 20, 'no_masking': True, 'original_map_path': './resource/usc.png', 'original_map_scale': 3.4375, 'preset_map_path': './resource/setup.json', 'ratio_coverage': 0.0125}, 'eval': {'evaluation_config': {'env_config': {'evaluation': True, 'n_maps': 3, 'preset_map_path': None}, 'explore': False}, 'evaluation_duration': 3, 'evaluation_interval': 5}, 'explore': {'exploration_config': {'epsilon_timesteps': 10, 'final_epsilon': 0.02, 'initial_epsilon': 1.0, 'type': 'EpsilonGreedy'}, 'explore': True}, 'report': {'min_sample_timesteps_per_iteration': 10}, 'resource': {'num_cpus_per_worker': 2, 'num_gpus': 0, 'num_gpus_per_worker': 0}, 'rollout': {'num_envs_per_worker': 1, 'num_rollout_workers': 4}, 'stop': {'training_iteration': 10}, 'train': {'optimization_config': {'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.001, 'entropy_learning_rate': 0.0001}, 'num_steps_sampled_before_learning_starts': 10, 'replay_buffer_config': {'capacity': 50000}, 'target_network_update_freq': 0, 'tau': 0.005, 'gamma': 0.1, 'grad_clip': 40.0, 'train_batch_size': 128}}
2024-02-22 01:37:39,018 INFO ================EVALUATION AT # 5================
2024-02-22 01:37:45,693 INFO ================EVALUATION AT # 10================
2024-02-22 01:37:47,888 INFO =============A WHOLE TRAINING PERIOD ENDED=============
2024-02-22 01:37:47,894 INFO agent_timesteps_total: 268
connector_metrics:
  ObsPreprocessorConnector_ms: 0.010106960932413736
  StateBufferConnector_ms: 0.0065962473551432295
  ViewRequirementAgentConnector_ms: 0.16309618949890137
counters:
  last_target_update_ts: 268
  num_agent_steps_sampled: 268
  num_agent_steps_trained: 8320
  num_env_steps_sampled: 268
  num_env_steps_trained: 8320
  num_target_updates: 65
custom_metrics: {}
date: 2024-02-22_01-37-47
done: false
episode_len_mean: 20.0
episode_media: {}
episode_reward_max: -2299.3674652334234
episode_reward_mean: -2627.129892389234
episode_reward_min: -3070.2468517810885
episodes_this_iter: 4
episodes_total: 12
evaluation:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0032107035319010415
    StateBufferConnector_ms: 0.001708666483561198
    ViewRequirementAgentConnector_ms: 0.03314812978108724
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -2448.6659275674574
  episode_reward_mean: -2686.8195253912445
  episode_reward_min: -3128.161814760888
  episodes_this_iter: 3
  hist_stats:
    episode_lengths:
    - 20
    - 20
    - 20
    episode_reward:
    - -3128.161814760888
    - -2483.630833845388
    - -2448.6659275674574
  num_agent_steps_sampled_this_iter: 60
  num_env_steps_sampled_this_iter: 60
  num_faulty_episodes: 0
  num_healthy_workers: 0
  num_in_flight_async_reqs: 0
  num_remote_worker_restarts: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.03916567022150213
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 14.220773681136201
    mean_inference_ms: 0.5510543003555172
    mean_raw_obs_processing_ms: 0.1563020974151359
  sampler_results:
    connector_metrics:
      ObsPreprocessorConnector_ms: 0.0032107035319010415
      StateBufferConnector_ms: 0.001708666483561198
      ViewRequirementAgentConnector_ms: 0.03314812978108724
    custom_metrics: {}
    episode_len_mean: 20.0
    episode_media: {}
    episode_reward_max: -2448.6659275674574
    episode_reward_mean: -2686.8195253912445
    episode_reward_min: -3128.161814760888
    episodes_this_iter: 3
    hist_stats:
      episode_lengths:
      - 20
      - 20
      - 20
      episode_reward:
      - -3128.161814760888
      - -2483.630833845388
      - -2448.6659275674574
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.03916567022150213
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 14.220773681136201
      mean_inference_ms: 0.5510543003555172
      mean_raw_obs_processing_ms: 0.1563020974151359
  timesteps_this_iter: 60
hostname: OrangeBookPro14.lan
info:
  last_target_update_ts: 268
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 64.0
      learner_stats:
        actor_loss: -8.20208740234375
        allreduce_latency: 0.0
        alpha_loss: -0.0005759955383837223
        alpha_value: 0.994007408618927
        critic_loss: 8.802786827087402
        grad_gnorm: 0.09582957625389099
        log_alpha_value: -0.006010623648762703
        max_q: 1.1756268739700317
        mean_q: -1.9282305240631104
        min_q: -339.46685791015625
        policy_t: 0.00024414059589616954
        target_entropy: 8.151411056518555
      mean_td_error: 38.05168151855469
      model: {}
      num_agent_steps_trained: 128.0
      num_grad_updates_lifetime: 65.0
      td_error: [2.2863082885742188, 15.616573333740234, 60.17992401123047, 22.021411895751953,
        164.05734252929688, 3.7837905883789062, 23.843242645263672, 34.233619689941406,
        11.631988525390625, 3.7837905883789062, 18.139667510986328, 24.720531463623047,
        6.4418182373046875, 68.93461608886719, 28.238494873046875, 7.969535827636719,
        10.531417846679688, 154.86480712890625, 24.720531463623047, 5.523193359375,
        27.560096740722656, 5.523193359375, 19.43195343017578, 10.531417846679688,
        6.4418182373046875, 29.408069610595703, 54.80535888671875, 72.28376007080078,
        3.7837905883789062, 128.77096557617188, 61.23111343383789, 18.171669006347656,
        54.80535888671875, 28.238494873046875, 58.914405822753906, 38.19330978393555,
        12.74697494506836, 40.95063781738281, 33.961490631103516, 61.23111343383789,
        28.238494873046875, 61.23111343383789, 19.87397003173828, 61.8358039855957,
        72.28376007080078, 24.654197692871094, 26.416397094726562, 11.172080993652344,
        33.961490631103516, 0.6272201538085938, 7.656961441040039, 11.172080993652344,
        154.86480712890625, 29.408069610595703, 61.8358039855957, 26.416397094726562,
        154.86480712890625, 61.8358039855957, 11.172080993652344, 11.172080993652344,
        4.711093902587891, 5.523193359375, 61.23111343383789, 7.3939666748046875,
        154.86480712890625, 33.961490631103516, 6.7447662353515625, 7.969535827636719,
        4.7587432861328125, 17.68286895751953, 61.8358039855957, 72.28376007080078,
        61.23111343383789, 19.43195343017578, 22.807437896728516, 22.021411895751953,
        61.23111343383789, 23.843242645263672, 69.42341613769531, 128.77096557617188,
        8.895126342773438, 38.19330978393555, 23.843242645263672, 61.8358039855957,
        27.560096740722656, 72.28376007080078, 71.95333862304688, 25.381614685058594,
        24.654197692871094, 71.95333862304688, 11.172080993652344, 14.532424926757812,
        6.492576599121094, 55.620296478271484, 71.95333862304688, 60.17992401123047,
        9.573814392089844, 6.4418182373046875, 11.631988525390625, 19.43195343017578,
        6.7447662353515625, 29.408069610595703, 21.357757568359375, 11.172080993652344,
        12.74697494506836, 41.69172668457031, 71.95333862304688, 7.3939666748046875,
        22.807437896728516, 3.7837905883789062, 15.616573333740234, 114.51115417480469,
        61.8358039855957, 12.114265441894531, 28.238494873046875, 21.436996459960938,
        72.28376007080078, 12.114265441894531, 12.74697494506836, 19.87397003173828,
        28.238494873046875, 164.05734252929688, 87.8747329711914, 19.87397003173828,
        12.114265441894531, 21.197349548339844, 54.80535888671875, 12.114265441894531]
  num_agent_steps_sampled: 268
  num_agent_steps_trained: 8320
  num_env_steps_sampled: 268
  num_env_steps_trained: 8320
  num_target_updates: 65
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 268
num_agent_steps_trained: 8320
num_env_steps_sampled: 268
num_env_steps_sampled_this_iter: 32
num_env_steps_sampled_throughput_per_sec: 30.30891544771443
num_env_steps_trained: 8320
num_env_steps_trained_this_iter: 1024
num_env_steps_trained_throughput_per_sec: 969.8852943268618
num_faulty_episodes: 0
num_healthy_workers: 4
num_in_flight_async_reqs: 0
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 1024
perf:
  cpu_util_percent: 31.233333333333334
  ram_util_percent: 81.10000000000001
pid: 96679
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10714400238141314
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 10.695193989384366
  mean_inference_ms: 2.254182226657468
  mean_raw_obs_processing_ms: 2.2121752059617514
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.010106960932413736
    StateBufferConnector_ms: 0.0065962473551432295
    ViewRequirementAgentConnector_ms: 0.16309618949890137
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -2299.3674652334234
  episode_reward_mean: -2627.129892389234
  episode_reward_min: -3070.2468517810885
  episodes_this_iter: 4
  hist_stats:
    episode_lengths: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
    episode_reward: [-2806.6297833123585, -2299.3674652334234, -2402.640333768177,
      -2846.183111533362, -2751.075164121097, -3070.2468517810885, -2541.033648725849,
      -2329.106809534522, -2694.0312832339155, -2762.5387794802264, -2356.4357899024694,
      -2666.2696880443204]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10714400238141314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 10.695193989384366
    mean_inference_ms: 2.254182226657468
    mean_raw_obs_processing_ms: 2.2121752059617514
time_since_restore: 13.639449119567871
time_this_iter_s: 2.184889793395996
time_total_s: 13.639449119567871
timers:
  learn_throughput: 4817.189
  learn_time_ms: 26.572
  load_throughput: 1820518.522
  load_time_ms: 0.07
  sample_time_ms: 55.411
  synch_weights_time_ms: 18.688
  training_iteration_time_ms: 129.329
timestamp: 1708594667
timesteps_total: 268
training_iteration: 10
trial_id: default

2024-02-22 01:37:47,894 DEBUG {'env': {'coefficient_dict': {'p_b': 1.0, 'p_d': 1.0, 'r_c': 0.1}, 'cropped_map_size': 64, 'n_maps': 100, 'n_steps_per_map': 20, 'no_masking': True, 'original_map_path': './resource/usc.png', 'original_map_scale': 3.4375, 'preset_map_path': './resource/setup.json', 'ratio_coverage': 0.0125}, 'eval': {'evaluation_config': {'env_config': {'evaluation': True, 'n_maps': 3, 'preset_map_path': None}, 'explore': False}, 'evaluation_duration': 3, 'evaluation_interval': 5}, 'explore': {'exploration_config': {'epsilon_timesteps': 10, 'final_epsilon': 0.02, 'initial_epsilon': 1.0, 'type': 'EpsilonGreedy'}, 'explore': True}, 'report': {'min_sample_timesteps_per_iteration': 10}, 'resource': {'num_cpus_per_worker': 2, 'num_gpus': 0, 'num_gpus_per_worker': 0}, 'rollout': {'num_envs_per_worker': 1, 'num_rollout_workers': 4}, 'stop': {'training_iteration': 10}, 'train': {'optimization_config': {'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.001, 'entropy_learning_rate': 0.0001}, 'num_steps_sampled_before_learning_starts': 10, 'replay_buffer_config': {'capacity': 50000}, 'target_network_update_freq': 0, 'tau': 0.005, 'gamma': 0.1, 'grad_clip': 40.0, 'train_batch_size': 128}}
2024-02-22 01:41:48,124 INFO ================EVALUATION AT # 5================
2024-02-22 01:42:05,747 INFO ================EVALUATION AT # 10================
2024-02-22 01:42:24,041 INFO ================EVALUATION AT # 15================
2024-02-22 01:42:41,724 INFO ================EVALUATION AT # 20================
2024-02-22 01:42:58,914 INFO ================EVALUATION AT # 25================
2024-02-22 01:43:17,615 INFO ================EVALUATION AT # 30================
2024-02-22 01:43:35,426 INFO ================EVALUATION AT # 35================
2024-02-22 01:43:53,059 INFO ================EVALUATION AT # 40================
2024-02-22 01:44:10,564 INFO ================EVALUATION AT # 45================
2024-02-22 01:44:28,089 INFO ================EVALUATION AT # 50================
2024-02-22 01:47:34,565 INFO ================EVALUATION AT # 55================
2024-02-22 01:51:19,695 INFO ================EVALUATION AT # 60================
2024-02-22 01:54:58,686 INFO ================EVALUATION AT # 65================
2024-02-22 01:58:22,042 INFO ================EVALUATION AT # 70================
2024-02-22 02:01:59,426 INFO ================EVALUATION AT # 75================
2024-02-22 02:05:38,408 INFO ================EVALUATION AT # 80================
2024-02-22 02:09:14,733 INFO ================EVALUATION AT # 85================
2024-02-22 02:12:52,207 INFO ================EVALUATION AT # 90================
2024-02-22 02:16:10,253 INFO ================EVALUATION AT # 95================
2024-02-22 02:19:30,549 INFO ================EVALUATION AT # 100================
2024-02-22 02:22:42,434 INFO ================EVALUATION AT # 105================
2024-02-22 02:25:51,795 INFO ================EVALUATION AT # 110================
2024-02-22 02:29:01,399 INFO ================EVALUATION AT # 115================
2024-02-22 02:32:17,657 INFO ================EVALUATION AT # 120================
2024-02-22 02:35:40,104 INFO ================EVALUATION AT # 125================
2024-02-22 02:38:53,991 INFO ================EVALUATION AT # 130================
2024-02-22 02:42:14,632 INFO ================EVALUATION AT # 135================
2024-02-22 02:45:26,947 INFO ================EVALUATION AT # 140================
2024-02-22 02:48:13,641 INFO ================EVALUATION AT # 145================
2024-02-22 02:50:57,254 INFO ================EVALUATION AT # 150================
2024-02-22 02:53:40,702 INFO ================EVALUATION AT # 155================
2024-02-22 02:56:24,746 INFO ================EVALUATION AT # 160================
2024-02-22 02:59:09,018 INFO ================EVALUATION AT # 165================
2024-02-22 03:01:57,855 INFO ================EVALUATION AT # 170================
2024-02-22 03:04:47,129 INFO ================EVALUATION AT # 175================
2024-02-22 03:07:31,429 INFO ================EVALUATION AT # 180================
2024-02-22 03:10:16,385 INFO ================EVALUATION AT # 185================
2024-02-22 03:13:03,867 INFO ================EVALUATION AT # 190================
2024-02-22 03:15:50,533 INFO ================EVALUATION AT # 195================
2024-02-22 03:18:44,319 INFO ================EVALUATION AT # 200================
2024-02-22 03:21:34,610 INFO ================EVALUATION AT # 205================
2024-02-22 03:24:21,796 INFO ================EVALUATION AT # 210================
2024-02-22 03:27:10,236 INFO ================EVALUATION AT # 215================
2024-02-22 03:30:01,416 INFO ================EVALUATION AT # 220================
2024-02-22 03:32:58,017 INFO ================EVALUATION AT # 225================
2024-02-22 03:35:43,243 INFO ================EVALUATION AT # 230================
2024-02-22 03:38:33,432 INFO ================EVALUATION AT # 235================
2024-02-22 03:41:26,063 INFO ================EVALUATION AT # 240================
2024-02-22 03:44:15,816 INFO ================EVALUATION AT # 245================
2024-02-22 03:47:05,000 INFO ================EVALUATION AT # 250================
2024-02-22 03:49:56,804 INFO ================EVALUATION AT # 255================
2024-02-22 03:52:51,263 INFO ================EVALUATION AT # 260================
2024-02-22 03:55:45,726 INFO ================EVALUATION AT # 265================
2024-02-22 03:58:39,637 INFO ================EVALUATION AT # 270================
2024-02-22 04:01:38,847 INFO ================EVALUATION AT # 275================
2024-02-22 04:04:40,570 INFO ================EVALUATION AT # 280================
2024-02-22 04:07:35,708 INFO ================EVALUATION AT # 285================
2024-02-22 04:10:34,272 INFO ================EVALUATION AT # 290================
2024-02-22 04:13:29,590 INFO ================EVALUATION AT # 295================
2024-02-22 04:16:24,945 INFO ================EVALUATION AT # 300================
2024-02-22 04:19:21,249 INFO ================EVALUATION AT # 305================
2024-02-22 04:22:15,963 INFO ================EVALUATION AT # 310================
2024-02-22 04:25:12,942 INFO ================EVALUATION AT # 315================
2024-02-22 04:28:10,391 INFO ================EVALUATION AT # 320================
2024-02-22 04:31:11,121 INFO ================EVALUATION AT # 325================
2024-02-22 04:34:08,916 INFO ================EVALUATION AT # 330================
2024-02-22 04:37:06,582 INFO ================EVALUATION AT # 335================
2024-02-22 04:40:09,746 INFO ================EVALUATION AT # 340================
2024-02-22 04:43:01,558 INFO ================EVALUATION AT # 345================
2024-02-22 04:45:53,327 INFO ================EVALUATION AT # 350================
2024-02-22 04:48:49,676 INFO ================EVALUATION AT # 355================
2024-02-22 04:51:44,991 INFO ================EVALUATION AT # 360================
2024-02-22 04:54:41,673 INFO ================EVALUATION AT # 365================
2024-02-22 04:57:45,210 INFO ================EVALUATION AT # 370================
2024-02-22 05:00:52,288 INFO ================EVALUATION AT # 375================
2024-02-22 05:03:52,237 INFO ================EVALUATION AT # 380================
2024-02-22 05:06:53,377 INFO ================EVALUATION AT # 385================
2024-02-22 05:10:01,503 INFO ================EVALUATION AT # 390================
2024-02-22 05:12:58,881 INFO ================EVALUATION AT # 395================
2024-02-22 05:15:55,661 INFO ================EVALUATION AT # 400================
2024-02-22 05:18:54,793 INFO ================EVALUATION AT # 405================
2024-02-22 05:21:53,235 INFO ================EVALUATION AT # 410================
2024-02-22 05:24:50,117 INFO ================EVALUATION AT # 415================
2024-02-22 05:27:47,404 INFO ================EVALUATION AT # 420================
2024-02-22 05:30:48,525 INFO ================EVALUATION AT # 425================
2024-02-22 05:33:50,601 INFO ================EVALUATION AT # 430================
2024-02-22 05:36:50,023 INFO ================EVALUATION AT # 435================
2024-02-22 05:40:02,408 INFO ================EVALUATION AT # 440================
2024-02-22 05:43:03,759 INFO ================EVALUATION AT # 445================
2024-02-22 05:46:01,885 INFO ================EVALUATION AT # 450================
2024-02-22 05:49:00,963 INFO ================EVALUATION AT # 455================
2024-02-22 05:52:05,214 INFO ================EVALUATION AT # 460================
2024-02-22 05:55:10,393 INFO ================EVALUATION AT # 465================
2024-02-22 05:58:14,245 INFO ================EVALUATION AT # 470================
2024-02-22 06:01:17,652 INFO ================EVALUATION AT # 475================
2024-02-22 06:04:20,318 INFO ================EVALUATION AT # 480================
2024-02-22 06:07:23,195 INFO ================EVALUATION AT # 485================
2024-02-22 06:10:35,412 INFO ================EVALUATION AT # 490================
2024-02-22 06:13:39,014 INFO ================EVALUATION AT # 495================
2024-02-22 06:16:41,007 INFO ================EVALUATION AT # 500================
2024-02-22 06:17:17,137 INFO =============A WHOLE TRAINING PERIOD ENDED=============
2024-02-22 06:17:17,145 INFO agent_timesteps_total: 500000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.008477926254272461
  StateBufferConnector_ms: 0.0046176910400390625
  ViewRequirementAgentConnector_ms: 0.13685870170593262
counters:
  last_target_update_ts: 500000
  num_agent_steps_sampled: 500000
  num_agent_steps_trained: 14400000
  num_env_steps_sampled: 500000
  num_env_steps_trained: 14400000
  num_target_updates: 112500
custom_metrics: {}
date: 2024-02-22_06-17-17
done: false
episode_len_mean: 20.0
episode_media: {}
episode_reward_max: -28.284271247461913
episode_reward_mean: -441.016750846498
episode_reward_min: -2641.8144406874912
episodes_this_iter: 51
episodes_total: 25163
evaluation:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0022649765014648438
    StateBufferConnector_ms: 0.0015815099080403645
    ViewRequirementAgentConnector_ms: 0.03447532653808594
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -748.2622246293479
  episode_reward_mean: -1239.3939996342358
  episode_reward_min: -2106.1110255092804
  episodes_this_iter: 3
  hist_stats:
    episode_lengths:
    - 20
    - 20
    - 20
    episode_reward:
    - -2106.1110255092804
    - -863.808748764079
    - -748.2622246293479
  num_agent_steps_sampled_this_iter: 60
  num_env_steps_sampled_this_iter: 60
  num_faulty_episodes: 0
  num_healthy_workers: 0
  num_in_flight_async_reqs: 0
  num_remote_worker_restarts: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.03522075309174952
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 11.155918267861423
    mean_inference_ms: 0.5513538302749103
    mean_raw_obs_processing_ms: 0.1568811334305814
  sampler_results:
    connector_metrics:
      ObsPreprocessorConnector_ms: 0.0022649765014648438
      StateBufferConnector_ms: 0.0015815099080403645
      ViewRequirementAgentConnector_ms: 0.03447532653808594
    custom_metrics: {}
    episode_len_mean: 20.0
    episode_media: {}
    episode_reward_max: -748.2622246293479
    episode_reward_mean: -1239.3939996342358
    episode_reward_min: -2106.1110255092804
    episodes_this_iter: 3
    hist_stats:
      episode_lengths:
      - 20
      - 20
      - 20
      episode_reward:
      - -2106.1110255092804
      - -863.808748764079
      - -748.2622246293479
    num_faulty_episodes: 0
    policy_reward_max: {}
    policy_reward_mean: {}
    policy_reward_min: {}
    sampler_perf:
      mean_action_processing_ms: 0.03522075309174952
      mean_env_render_ms: 0.0
      mean_env_wait_ms: 11.155918267861423
      mean_inference_ms: 0.5513538302749103
      mean_raw_obs_processing_ms: 0.1568811334305814
  timesteps_this_iter: 60
hostname: OrangeBookPro14.lan
info:
  last_target_update_ts: 500000
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 112499.0
      learner_stats:
        actor_loss: -319.7539978027344
        allreduce_latency: 0.0
        alpha_loss: -0.017553135752677917
        alpha_value: 46.74486541748047
        critic_loss: 0.12206102907657623
        grad_gnorm: 0.0045655351132154465
        log_alpha_value: 3.8447043895721436
        max_q: 31.468252182006836
        mean_q: -77.76947784423828
        min_q: -398.43206787109375
        policy_t: 0.000244140625
        target_entropy: 8.151411056518555
      mean_td_error: 1.100489854812622
      model: {}
      num_agent_steps_trained: 128.0
      num_grad_updates_lifetime: 112500.0
      td_error: [0.7416138648986816, 0.07272911071777344, 0.3099174499511719, 0.06061363220214844,
        0.8277359008789062, 0.07116222381591797, 0.4787178039550781, 4.880409240722656,
        0.14172744750976562, 0.24291658401489258, 2.03497314453125, 0.5374449491500854,
        0.59716796875, 0.20055007934570312, 0.20480871200561523, 0.504396915435791,
        0.2760143280029297, 0.11641407012939453, 0.5587162971496582, 0.0367584228515625,
        0.08048439025878906, 0.28121843934059143, 0.5274887084960938, 0.9788436889648438,
        0.5173358917236328, 0.5901718139648438, 0.1305832862854004, 0.36953020095825195,
        8.982414245605469, 0.43741607666015625, 0.31845855712890625, 0.8248484134674072,
        1.2262516021728516, 0.15668916702270508, 0.9409356117248535, 0.3582124710083008,
        0.8990678787231445, 0.045160770416259766, 0.7594490051269531, 0.7263259887695312,
        0.20112180709838867, 0.19273948669433594, 1.145080327987671, 0.21765995025634766,
        0.2239694595336914, 0.4533240795135498, 0.41379523277282715, 0.9100456237792969,
        1.7885122299194336, 0.5214204788208008, 0.6200189590454102, 0.18005508184432983,
        0.10823631286621094, 0.18620586395263672, 0.31703758239746094, 0.20055007934570312,
        0.3249223232269287, 0.7075493335723877, 0.09199142456054688, 0.48719310760498047,
        4.422632217407227, 0.49439170956611633, 0.3114480972290039, 0.3563575744628906,
        0.10383892059326172, 0.07929611206054688, 0.28534603118896484, 0.27569007873535156,
        1.145080327987671, 0.06079864501953125, 0.15668916702270508, 0.11342597007751465,
        0.31626033782958984, 0.8868598937988281, 0.4715452194213867, 1.0602645874023438,
        0.1884922981262207, 0.08844947814941406, 2.718292236328125, 40.41374588012695,
        1.3435707092285156, 0.0782935619354248, 0.1260356903076172, 0.1305832862854004,
        2.717449188232422, 2.354450225830078, 0.7590694427490234, 0.15813541412353516,
        0.24737167358398438, 0.24341106414794922, 1.3234264850616455, 0.15760022401809692,
        0.18843287229537964, 0.08122050762176514, 0.18675708770751953, 1.9724807739257812,
        0.30109405517578125, 0.283843994140625, 9.85989761352539, 0.050258517265319824,
        4.168693542480469, 0.3870372772216797, 0.12228965759277344, 0.9790611267089844,
        0.21250677108764648, 0.1466541290283203, 0.5267255306243896, 0.3037419319152832,
        1.0147857666015625, 5.311481475830078, 0.19503164291381836, 0.6709814071655273,
        0.3114480972290039, 0.15760022401809692, 0.2880878448486328, 0.08045005798339844,
        0.43358898162841797, 0.19902372360229492, 0.8277359008789062, 0.2916994094848633,
        0.7416138648986816, 0.7953262329101562, 0.3024214506149292, 0.6200189590454102,
        0.730595588684082, 0.8277359008789062, 0.5901718139648438, 1.7768006324768066]
  num_agent_steps_sampled: 500000
  num_agent_steps_trained: 14400000
  num_env_steps_sampled: 500000
  num_env_steps_trained: 14400000
  num_target_updates: 112500
iterations_since_restore: 500
node_ip: 127.0.0.1
num_agent_steps_sampled: 500000
num_agent_steps_trained: 14400000
num_env_steps_sampled: 500000
num_env_steps_sampled_this_iter: 1000
num_env_steps_sampled_throughput_per_sec: 28.303726995964197
num_env_steps_trained: 14400000
num_env_steps_trained_this_iter: 32000
num_env_steps_trained_throughput_per_sec: 905.7192638708543
num_faulty_episodes: 0
num_healthy_workers: 4
num_in_flight_async_reqs: 0
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 32000
perf:
  cpu_util_percent: 61.288000000000004
  ram_util_percent: 80.152
pid: 96827
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06916874391351997
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 9.697645349022737
  mean_inference_ms: 1.3232661084812773
  mean_raw_obs_processing_ms: 0.6825093421110944
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.008477926254272461
    StateBufferConnector_ms: 0.0046176910400390625
    ViewRequirementAgentConnector_ms: 0.13685870170593262
  custom_metrics: {}
  episode_len_mean: 20.0
  episode_media: {}
  episode_reward_max: -28.284271247461913
  episode_reward_mean: -441.016750846498
  episode_reward_min: -2641.8144406874912
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
      20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,
      20, 20, 20, 20, 20, 20, 20, 20, 20]
    episode_reward: [-363.84887978899616, -309.7056274847715, -558.2752145222757,
      -384.0050895855265, -436.83189157584593, -76.7213595499958, -275.6067977499789,
      -168.00000000000006, -770.1595605472347, -223.70329614269002, -201.6021977856104,
      -647.9126028197401, -368.58772731852804, -391.2043955712205, -465.9898987322333,
      -776.965751817893, -257.1077027627484, -327.7056274847713, -258.8800749063506,
      -739.5842619895277, -169.98039027185564, -143.98039027185573, -746.0903313516362,
      -38.2842712474619, -30.0, -79.24555320336762, -120.11102550927976, -410.32815729997503,
      -256.61903789690604, -2250.3672458864644, -961.3681305911332, -44.72135954999578,
      -530.5187029830385, -509.32830820770914, -266.04650534085243, -417.8810752881292,
      -562.3448553724736, -237.70329614269016, -92.56854249492383, -473.0589287593181,
      -518.5483399593907, -499.25353003264144, -207.83154621172787, -576.2608082460457,
      -75.24555320336759, -562.9089116420447, -624.9691346263317, -560.4996878900157,
      -372.60530795876747, -75.24555320336759, -610.0, -250.67962264113197, -226.9877312976487,
      -79.24555320336762, -94.72135954999575, -610.0, -478.2725046566046, -72.11102550927978,
      -28.284271247461913, -586.6342439892263, -530.2154055254969, -436.83189157584593,
      -108.11102550927983, -518.7127774109849, -452.7564357995464, -2408.131112314674,
      -460.75660333228177, -2641.8144406874912, -221.99999999999994, -450.22776601683773,
      -703.0482123511185, -668.3060268852503, -434.8427124746192, -109.44271909999154,
      -551.5098860845803, -151.99999999999994, -212.2220510185595, -372.68093624485806,
      -119.24555320336763, -376.0000000000001, -58.72135954999579, -312.8705831449919,
      -407.329537415253, -645.7727756146212, -580.0939982143926, -677.6406376870351,
      -405.7708763999664, -251.4213562373095, -151.99999999999994, -405.29646120466816,
      -447.63083384538817, -589.0044071459762, -492.044159301569, -217.29999999999995,
      -608.3564212655272, -388.84271247461913, -661.7544991609997, -684.0428203930336,
      -467.6308338453882, -266.04650534085243]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06916874391351997
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 9.697645349022737
    mean_inference_ms: 1.3232661084812773
    mean_raw_obs_processing_ms: 0.6825093421110944
time_since_restore: 16537.691917419434
time_this_iter_s: 36.11893606185913
time_total_s: 16537.691917419434
timers:
  learn_throughput: 5226.466
  learn_time_ms: 24.491
  load_throughput: 1698958.582
  load_time_ms: 0.075
  sample_time_ms: 57.73
  synch_weights_time_ms: 16.523
  training_iteration_time_ms: 127.052
timestamp: 1708611437
timesteps_total: 500000
training_iteration: 500
trial_id: default

2024-02-22 06:17:17,145 DEBUG {'env': {'coefficient_dict': {'p_b': 1.0, 'p_d': 1.0, 'r_c': 0.1}, 'cropped_map_size': 64, 'n_maps': 400, 'n_steps_per_map': 20, 'no_masking': True, 'original_map_path': './resource/usc.png', 'original_map_scale': 3.4375, 'preset_map_path': './resource/setup_400.json', 'ratio_coverage': 0.0125}, 'eval': {'evaluation_config': {'env_config': {'evaluation': True, 'n_maps': 3, 'preset_map_path': None}, 'explore': False}, 'evaluation_duration': 3, 'evaluation_interval': 5}, 'explore': {'exploration_config': {'epsilon_timesteps': 100000, 'final_epsilon': 0.02, 'initial_epsilon': 1.0, 'type': 'EpsilonGreedy'}, 'explore': True}, 'report': {'min_sample_timesteps_per_iteration': 1000}, 'resource': {'num_cpus_per_worker': 2, 'num_gpus': 0, 'num_gpus_per_worker': 0}, 'rollout': {'num_envs_per_worker': 1, 'num_rollout_workers': 4}, 'stop': {'training_iteration': 500}, 'train': {'optimization_config': {'actor_learning_rate': 0.0001, 'critic_learning_rate': 0.001, 'entropy_learning_rate': 0.0001}, 'num_steps_sampled_before_learning_starts': 50000, 'replay_buffer_config': {'capacity': 50000}, 'target_network_update_freq': 0, 'tau': 0.005, 'gamma': 0.1, 'grad_clip': 40.0, 'train_batch_size': 128}}
